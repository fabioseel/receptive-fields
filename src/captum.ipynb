{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda\n"
     ]
    }
   ],
   "source": [
    "from captum.attr import NeuronGradient\n",
    "from receptive_fields.util.experiment_setup import open_experiment\n",
    "from receptive_fields.util.modules import NamedFromSequential\n",
    "import torch\n",
    "from torchinfo import summary\n",
    "from util.activation_visualization import rescaleZeroOne\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "model_path = \"../models/areadne_submission/pool_large\"\n",
    "model, train_data= open_experiment(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_model = NamedFromSequential(model.get_sequential()) # TODO: Get Sequential should return individual objects for activation functions etc instead of references!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NamedFromSequential(\n",
       "  (Conv2d_0): Conv2d(3, 32, kernel_size=(7, 7), stride=(1, 1))\n",
       "  (ELU_0): ELU(alpha=1.0, inplace=True)\n",
       "  (AvgPool2d_0): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "  (Conv2d_1): Conv2d(32, 32, kernel_size=(7, 7), stride=(1, 1))\n",
       "  (ELU_1): ELU(alpha=1.0, inplace=True)\n",
       "  (AvgPool2d_1): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "  (Conv2d_2): Conv2d(32, 32, kernel_size=(7, 7), stride=(1, 1))\n",
       "  (ELU_2): ELU(alpha=1.0, inplace=True)\n",
       "  (AvgPool2d_2): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "  (Conv2d_3): Conv2d(32, 32, kernel_size=(7, 7), stride=(1, 1))\n",
       "  (ELU_3): ELU(alpha=1.0, inplace=True)\n",
       "  (AvgPool2d_3): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "  (Flatten_0): Flatten(start_dim=1, end_dim=-1)\n",
       "  (Linear_0): Linear(in_features=128, out_features=128, bias=True)\n",
       "  (ELU_4): ELU(alpha=1.0, inplace=True)\n",
       "  (Linear_1): Linear(in_features=128, out_features=128, bias=True)\n",
       "  (ELU_5): ELU(alpha=1.0, inplace=True)\n",
       "  (Linear_2): Linear(in_features=128, out_features=128, bias=True)\n",
       "  (ELU_6): ELU(alpha=1.0, inplace=True)\n",
       "  (Linear_3): Linear(in_features=128, out_features=10, bias=True)\n",
       "  (Softmax_0): Softmax(dim=-1)\n",
       ")"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Cannot choose target column with output shape torch.Size([1, 128]).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[104], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m grad \u001b[38;5;241m=\u001b[39m NeuronGradient(seq_model, seq_model\u001b[38;5;241m.\u001b[39mELU_0)\n\u001b[0;32m----> 2\u001b[0m rf \u001b[38;5;241m=\u001b[39m grad\u001b[38;5;241m.\u001b[39mattribute(torch\u001b[38;5;241m.\u001b[39mzeros(\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m3\u001b[39m,\u001b[38;5;241m*\u001b[39mmodel\u001b[38;5;241m.\u001b[39mimg_size[::\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m], requires_grad\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m), neuron_selector\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m0\u001b[39m))\n\u001b[1;32m      3\u001b[0m plt\u001b[38;5;241m.\u001b[39mimshow(rescaleZeroOne(rf[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mmovedim(\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m2\u001b[39m)\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mcpu()))\n",
      "File \u001b[0;32m~/miniconda3/envs/receptive-fields/lib/python3.11/site-packages/captum/log/__init__.py:42\u001b[0m, in \u001b[0;36mlog_usage.<locals>._log_usage.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(func)\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m---> 42\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/receptive-fields/lib/python3.11/site-packages/captum/attr/_core/neuron/neuron_gradient.py:168\u001b[0m, in \u001b[0;36mNeuronGradient.attribute\u001b[0;34m(self, inputs, neuron_selector, additional_forward_args, attribute_to_neuron_input)\u001b[0m\n\u001b[1;32m    163\u001b[0m additional_forward_args \u001b[38;5;241m=\u001b[39m _format_additional_forward_args(\n\u001b[1;32m    164\u001b[0m     additional_forward_args\n\u001b[1;32m    165\u001b[0m )\n\u001b[1;32m    166\u001b[0m gradient_mask \u001b[38;5;241m=\u001b[39m apply_gradient_requirements(inputs)\n\u001b[0;32m--> 168\u001b[0m _, input_grads \u001b[38;5;241m=\u001b[39m _forward_layer_eval_with_neuron_grads(\n\u001b[1;32m    169\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mforward_func,\n\u001b[1;32m    170\u001b[0m     inputs,\n\u001b[1;32m    171\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayer,\n\u001b[1;32m    172\u001b[0m     additional_forward_args,\n\u001b[1;32m    173\u001b[0m     gradient_neuron_selector\u001b[38;5;241m=\u001b[39mneuron_selector,\n\u001b[1;32m    174\u001b[0m     device_ids\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice_ids,\n\u001b[1;32m    175\u001b[0m     attribute_to_layer_input\u001b[38;5;241m=\u001b[39mattribute_to_neuron_input,\n\u001b[1;32m    176\u001b[0m )\n\u001b[1;32m    178\u001b[0m undo_gradient_requirements(inputs, gradient_mask)\n\u001b[1;32m    179\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _format_output(is_inputs_tuple, input_grads)\n",
      "File \u001b[0;32m~/miniconda3/envs/receptive-fields/lib/python3.11/site-packages/captum/_utils/gradient.py:461\u001b[0m, in \u001b[0;36m_forward_layer_eval_with_neuron_grads\u001b[0;34m(forward_fn, inputs, layer, additional_forward_args, gradient_neuron_selector, grad_enabled, device_ids, attribute_to_layer_input)\u001b[0m\n\u001b[1;32m    457\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m gradient_neuron_selector \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    458\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\n\u001b[1;32m    459\u001b[0m         layer, Module\n\u001b[1;32m    460\u001b[0m     ), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot compute neuron gradients for multiple layers simultaneously!\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 461\u001b[0m     inp_grads \u001b[38;5;241m=\u001b[39m _neuron_gradients(\n\u001b[1;32m    462\u001b[0m         inputs, saved_layer[layer], key_list, gradient_neuron_selector\n\u001b[1;32m    463\u001b[0m     )\n\u001b[1;32m    464\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[1;32m    465\u001b[0m         _gather_distributed_tensors(saved_layer[layer], key_list\u001b[38;5;241m=\u001b[39mkey_list),\n\u001b[1;32m    466\u001b[0m         inp_grads,\n\u001b[1;32m    467\u001b[0m     )\n\u001b[1;32m    468\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/receptive-fields/lib/python3.11/site-packages/captum/_utils/gradient.py:132\u001b[0m, in \u001b[0;36m_neuron_gradients\u001b[0;34m(inputs, saved_layer, key_list, gradient_neuron_selector)\u001b[0m\n\u001b[1;32m    130\u001b[0m gradient_tensors \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    131\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m key_list:\n\u001b[0;32m--> 132\u001b[0m     current_out_tensor \u001b[38;5;241m=\u001b[39m _verify_select_neuron(\n\u001b[1;32m    133\u001b[0m         saved_layer[key], gradient_neuron_selector\n\u001b[1;32m    134\u001b[0m     )\n\u001b[1;32m    135\u001b[0m     gradient_tensors\u001b[38;5;241m.\u001b[39mappend(\n\u001b[1;32m    136\u001b[0m         torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mgrad(\n\u001b[1;32m    137\u001b[0m             torch\u001b[38;5;241m.\u001b[39munbind(current_out_tensor)\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    141\u001b[0m         )\n\u001b[1;32m    142\u001b[0m     )\n\u001b[1;32m    143\u001b[0m _total_gradients \u001b[38;5;241m=\u001b[39m _reduce_list(gradient_tensors, \u001b[38;5;28msum\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/receptive-fields/lib/python3.11/site-packages/captum/_utils/common.py:563\u001b[0m, in \u001b[0;36m_verify_select_neuron\u001b[0;34m(layer_output, selector)\u001b[0m\n\u001b[1;32m    556\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m selector(layer_output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(layer_output) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m layer_output[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m    558\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(layer_output) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m, (\n\u001b[1;32m    559\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot select neuron index from layer with multiple tensors,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    560\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconsider providing a neuron selector function instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    561\u001b[0m )\n\u001b[0;32m--> 563\u001b[0m selected_neurons \u001b[38;5;241m=\u001b[39m _verify_select_column(layer_output[\u001b[38;5;241m0\u001b[39m], selector)\n\u001b[1;32m    564\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _contains_slice(selector):\n\u001b[1;32m    565\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m selected_neurons\u001b[38;5;241m.\u001b[39mreshape(selected_neurons\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39msum(\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/receptive-fields/lib/python3.11/site-packages/captum/_utils/common.py:546\u001b[0m, in \u001b[0;36m_verify_select_column\u001b[0;34m(output, target)\u001b[0m\n\u001b[1;32m    541\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_verify_select_column\u001b[39m(\n\u001b[1;32m    542\u001b[0m     output: Tensor, target: Union[\u001b[38;5;28mint\u001b[39m, Tuple[Union[\u001b[38;5;28mint\u001b[39m, \u001b[38;5;28mslice\u001b[39m], \u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m]]\n\u001b[1;32m    543\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m    544\u001b[0m     target \u001b[38;5;241m=\u001b[39m (target,) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(target, \u001b[38;5;28mint\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m target\n\u001b[1;32m    545\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m (\n\u001b[0;32m--> 546\u001b[0m         \u001b[38;5;28mlen\u001b[39m(target) \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(output\u001b[38;5;241m.\u001b[39mshape) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    547\u001b[0m     ), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot choose target column with output shape \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (output\u001b[38;5;241m.\u001b[39mshape,)\n\u001b[1;32m    548\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output[(\u001b[38;5;28mslice\u001b[39m(\u001b[38;5;28;01mNone\u001b[39;00m), \u001b[38;5;241m*\u001b[39mtarget)]\n",
      "\u001b[0;31mAssertionError\u001b[0m: Cannot choose target column with output shape torch.Size([1, 128])."
     ]
    }
   ],
   "source": [
    "grad = NeuronGradient(seq_model, seq_model.ELU_0)\n",
    "rf = grad.attribute(torch.zeros(1,3,*model.img_size[::-1], requires_grad=True), neuron_selector=(1,0,0))\n",
    "plt.imshow(rescaleZeroOne(rf[0].movedim(0,2).detach().cpu()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "receptive-fields",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.1.undefined"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
