# Update 2024-04-10

## Classification of RFs
- improved synthetic generation
- mini-side-project: labeling gui
  - works fine, relabeled the dataset
  - (actually, I found a paper claiming that improving labels should be avoided as labeling additional data is more efficient...)
- still not quite satisfied with classification accuracy...
  - simplify / merge classes (potentially hierarchical evaluation later...)
    - gabors/simple edge
    - center surround
    - color
    - noise / unclassifiable / multifrequency?

## News on the Theory & reading front
- Gabors are eigenfunctions of convolution operator
  - but why should that make a CNN learn them?
    - adaptation rather to input then operator itself?
    - neuro equivalent (weight sharing across neurons)
    - other research in that domain?
  - fast experiments: convolve noise over itself
    - tendency to show high frequencies
    - not really "stable"
    - 
- "early" papers already wondering why gabors arise sometimes "late" (layer three):
  - also: gabors emerge naturally at 3rd layer without bottleneck, center surrounds in l1 + l2?
  - currently trying to track down research following that (All Convolutional Net, 2015)
![All Convolutional Net (2015)](image-31.png)

## Progress towards NeurIPS
- seems more and more unrealistic at this point...
- rather continue working on theory & have a nice poster at AREADNE & wrap that into paper when enough results are out